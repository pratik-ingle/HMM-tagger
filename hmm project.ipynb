{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import brown\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# frequency function \n",
    "def fre(x):\n",
    "    from collections import Counter\n",
    "    types =  Counter(tuple(x) for x in x )\n",
    "    #print(types)  # types is in the form of directories\n",
    "\n",
    "    # converting dictionary into two dimentional array \n",
    "    freq = []\n",
    "    for value in types.items() :\n",
    "        freq.append(value)\n",
    "\n",
    "    #sorting array  in decending order\n",
    "    def sortthird(freq): \n",
    "        return freq[1] \n",
    "    freq.sort(key = sortthird ,reverse = True) \n",
    "    #print(freq)\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert start \"<s>\" and end \"<\\s>\" symbols for each sentence \n",
    "p = brown.tagged_sents()\n",
    "brown_corpus = []\n",
    "for i in p :\n",
    "    i.insert(0,('<s>','<s>'))\n",
    "    i.insert(len(i),('<\\s>','<\\s>'))\n",
    "    brown_corpus.append(i)\n",
    "    \n",
    "# creating test and training sets from brown corpus\n",
    "#test set containt first 100 sentences for testing porpuse\n",
    "brown_test = []\n",
    "brown_train = []\n",
    "sen = 0\n",
    "for i in brown_corpus:\n",
    "    sen += 1\n",
    "    if sen <= 10:\n",
    "        brown_test.append(i)\n",
    "    else:\n",
    "        brown_train.append(i)\n",
    "        \n",
    "#considering training set as only [word , tag] insted of sentence \n",
    "brown_words_tag = []\n",
    "for i in brown_train:\n",
    "    for j in i:\n",
    "        brown_words_tag.append(j)\n",
    "        \n",
    "# frequency of brown_words_tag\n",
    "fre_wordtag = fre(brown_words_tag)\n",
    "#print(fre_wordtag)\n",
    "\n",
    "#frerquency of ti (tag) \n",
    "brown_tag = []\n",
    "for i in brown_train:\n",
    "    for j in i:\n",
    "         brown_tag.append(j[1])\n",
    "\n",
    "# getting frequency of brown_tag\n",
    "types =  collections.Counter(brown_tag)\n",
    "#print(types)  # types is in the form of directories\n",
    "\n",
    "# converting dictionary into two dimentional array \"a\"\n",
    "fre_tag = []\n",
    "for value in types.items() :\n",
    "    fre_tag.append(value)\n",
    "\n",
    "#sorting array in decending order\n",
    "def sortthird(fre_tag): \n",
    "    return fre_tag[1] \n",
    "fre_tag.sort(key = sortthird ,reverse = True) \n",
    "#print(fre_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# probabitity of p(wi|ti)\n",
    "probWiti = []\n",
    "list1 =[]\n",
    "list2 = []\n",
    "list3 = []\n",
    "for i in fre_wordtag:\n",
    "    for j in fre_tag:\n",
    "        if i[0][1] == j[0]:\n",
    "            temp = [i[0] , i[1]/j[1]]\n",
    "            probWiti.append(temp)\n",
    "            list1.append(i[0][0])\n",
    "            temp1 = [i[0][1], i[1]/j[1]]\n",
    "            list2.append(temp1)\n",
    "\n",
    "#probWiti\n",
    "\n",
    "#probability of p{ti|t(i-1)}\n",
    "\n",
    "#frequency of bigram taggs\n",
    "bi_tag = []\n",
    "x = len(brown_words_tag)\n",
    "for j in range(x):\n",
    "    if j+1 < x:  \n",
    "        temp = [brown_words_tag[j][1] , brown_words_tag[j+1][1]]\n",
    "        if temp != ['<\\s>' ,'<s>' ]: # not cosidering ['<\\s>' ,'<s>'] count b/z it's a end of sentance \n",
    "            bi_tag.append(temp)\n",
    "\n",
    "# frequency of \n",
    "fre_bi_tag= fre(bi_tag)\n",
    "#print(fre_bi_tag)\n",
    "\n",
    "# probabitity of p(wi|ti)\n",
    "probbitag = []\n",
    "for i in fre_bi_tag:\n",
    "    for j in fre_tag:\n",
    "        if i[0][0] == j[0]:\n",
    "            temp = [i[0] , i[1]/j[1]]\n",
    "            probbitag.append(temp)\n",
    "\n",
    "#probbitag\n",
    "\n",
    "# set of all differet tags present in brown corpus\n",
    "#since the probability of word depending on tag and probability of tag depeds on its previous tag there should not be any unk tag present\n",
    "# in HMM tagger\n",
    "pos_tag = [] \n",
    "for i in fre_tag:\n",
    "    pos_tag.append(i[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>', '<s>'), ('The', 'AT-TL'), ('jury', 'NN-HL'), ('said', 'VBD'), ('it', 'PPS-HL'), ('did', 'DOD-NC'), ('find', 'VB'), ('that', 'WPS-NC'), ('many', 'AP-NC'), ('of', 'IN-TL'), (\"Georgia's\", 'NP$'), ('registration', 'NN'), ('and', 'CC-HL'), ('election', 'NN'), ('laws', 'NNS'), ('``', '``'), ('are', 'BER-HL'), ('outmoded', 'JJ'), ('or', 'CC-NC'), ('inadequate', 'JJ'), ('and', 'CC-HL'), ('often', 'RB'), ('ambiguous', 'JJ'), (\"''\", \"''\"), ('.', '.-HL'), ('<\\\\s>', '<\\\\s>')] \n",
      " 5.0121351597188597e-33\n",
      "accuracy of HMM tagger for given sentance is \n",
      "53.84615384615385\n"
     ]
    }
   ],
   "source": [
    "# vitervi algorithm\n",
    "\n",
    "# creating lattice of transition and emissions probability\n",
    "for j in probWiti:\n",
    "    j[0][0]\n",
    "        \n",
    "      \n",
    "\n",
    "#emission probability for this sentance\n",
    "l = len(sentance)\n",
    "c = 1\n",
    "sentance = brown_test[4]    # change the sentance by replacing sentance number in brown_test out of first 10 sentances\n",
    "lattic_emission = [[] for i in range(l)]  #emission probability lattic\n",
    "sen_tag = []                              #set of all different tags sentance can have \n",
    "for i in range(l):\n",
    "    for j in probWiti:\n",
    "        if sentance[i][0] == j[0][0]: \n",
    "            lattic_emission[i].append(j) #lattice will only have element whose emission probability > 0, b/z for 0 emission probability final probability become zero\n",
    "            if j[0][1] not in sen_tag:\n",
    "                sen_tag.append(j[0][1]) #set of all posible taggs s sentance can have\n",
    "    if(len(lattic_emission[i])== 0):    #for unknown words in sentance \n",
    "        temp = [(sentance[i][0], 'NN') , 0.11 ] # unk are consider as 'NN' with probability of 0.11 b/w 11% accuracy is for unknoen wors as ' \n",
    "        lattic_emission[i].append(temp)\n",
    "                \n",
    "       \n",
    "            \n",
    "#transition tags for this sentance\n",
    "l = len(sen_tag) \n",
    "tran_tag = []\n",
    "for i in sen_tag:\n",
    "    for j in sen_tag:\n",
    "        temp = (i , j)\n",
    "        if temp not in tran_tag: # avoid repetitions \n",
    "            tran_tag.append(temp)\n",
    "            \n",
    "\n",
    "            \n",
    "#transition probability for this sentance\n",
    "tran_pro = []\n",
    "for i in tran_tag:\n",
    "    for j in probbitag:\n",
    "        if i == j[0]:  \n",
    "            tran_pro.append(j) # the tag pairs not in probbitag have zero probability again we are not considering them since result for such sentace will have 0 probability\n",
    "mat = []\n",
    "for i in lattic_emission:\n",
    "    temp = [i[0][0][0], len(i)]\n",
    "    mat.append(temp)       # number of possible tags outcomes for given word in a given sentance \n",
    "\n",
    "max_emission = []\n",
    "sequence = []\n",
    "for i in lattic_emission:\n",
    "    def sortthird(i): \n",
    "        return i[1] \n",
    "    i.sort(key = sortthird ,reverse = True) # getting maximum emission probability after each step\n",
    "    max_emission.append(i)\n",
    "l = len(mat)\n",
    "vi = []\n",
    "for i in range(l-1):\n",
    "    if i < l:\n",
    "        temp =(max_emission[i][0][0][1],max_emission[i+1][0][0][1])\n",
    "        vi.append(temp)\n",
    "        sequence.append(max_emission[i][0][0])\n",
    "temp = ('<\\s>', '<\\s>')\n",
    "sequence.append(temp)\n",
    "l = len(vi)\n",
    "Vj = [] #argmax from probability multiplication of transition and emission probabilities \n",
    "m = 0\n",
    "for i in range(l):\n",
    "    for j in tran_pro:\n",
    "        m += 1\n",
    "        if vi[i] == j[0]:\n",
    "            temp = max_emission[i][0][1]*j[1]\n",
    "            Vj.append(temp)\n",
    "            temp1= [max_emission[i][0][0],j[0]]\n",
    "    temp1= [max_emission[i][0][0],j[0]]\n",
    "    if(temp1 not in sequence):\n",
    "        temp1= [max_emission[i][0][0],j[0]]\n",
    "        \n",
    "def viterbi(Vj) : \n",
    "    result = 1\n",
    "    for x in Vj: \n",
    "         result = result * x  \n",
    "    return result         \n",
    "Viterbi = viterbi(Vj)\n",
    "print(sequence , '\\n' ,Viterbi)\n",
    "\n",
    "# the accuracy \n",
    "l = len(sentance)\n",
    "count = 0\n",
    "for i in range(l):\n",
    "    if sentance[i] == sequence[i]:\n",
    "        count +=1\n",
    "accuracy = (count / len(sentance))*100\n",
    "print(\"accuracy of HMM tagger for given sentance is \")\n",
    "print(accuracy)     # we are getting accuracy less because of prase types, different prase futher have different pos tags which are algorithm does not consider some time \n",
    "\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
